{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras \n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras \n",
    "import random\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, BatchNormalization, Activation, concatenate, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "import warnings\n",
    "import keras.backend as K \n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(7)\n",
    "random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "\n",
    "def chk(x):  \n",
    "    grid = x[:,:,14]\n",
    "    for i in range(40): \n",
    "        for j in range(40): \n",
    "            if grid[i][j] < 0: \n",
    "                return False \n",
    "    return True  \n",
    "\n",
    "def balance(x):  \n",
    "    return np.sum(x[:,:,14]) >= 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced = np.load('./storage/balancedtrainfiles.npy') \n",
    "#train = [] \n",
    "#for file in balanced: \n",
    "#    data = np.load(file).astype('float32') \n",
    "#    train.append(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31406, 40, 40, 15)\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir('./storage/train_proc')\n",
    "submission = pd.read_csv('./storage/sample_submission.csv')\n",
    "\n",
    "train = []\n",
    "cnt = 0 \n",
    "for file in train_files: \n",
    "    data = np.load('./storage/train_proc/'+file).astype('float32') \n",
    "    train.append(data)\n",
    "        \n",
    "        \n",
    "#test = []\n",
    "#for sub_id in submission['id']:\n",
    "#    data = np.load('./storage/test/'+'subset_'+sub_id+'.npy').astype('float32')\n",
    "#    test.append(data)\n",
    "train = np.array(train)\n",
    "#test = np.array(test) \n",
    "\n",
    "print(train.shape) \n",
    "#print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[:,:,:,:10]\n",
    "y_train = train[:,:,:,14]\n",
    "\n",
    "del train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs):\n",
    "\n",
    "    bn = BatchNormalization()(inputs)\n",
    "    conv0 = Conv2D(256, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
    "\n",
    "    bn = BatchNormalization()(conv0)\n",
    "    bn = Dropout(0.2)(bn) \n",
    "    conv = Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    concat = concatenate([conv0, conv], axis=3)\n",
    "\n",
    "    bn = BatchNormalization()(concat) \n",
    "    bn = Dropout(0.2)(bn)\n",
    "    conv = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
    "    concat = concatenate([concat, conv], axis=3)\n",
    "    \n",
    "    for i in range(12):\n",
    "        bn = BatchNormalization()(concat) \n",
    "        bn = Dropout(0.2)(bn) \n",
    "        conv = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
    "        concat = concatenate([concat, conv], axis=3)\n",
    "\n",
    "    bn = BatchNormalization()(concat)\n",
    "    outputs = Conv2D(1, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "input_layer = Input((40, 40, 10))\n",
    "model = build_model(input_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def custom_loss(y_true, y_pred): \n",
    "    y_true = K.flatten(y_true) \n",
    "    y_pred = K.flatten(y_pred) \n",
    "    MAE = K.mean(K.abs(y_true-y_pred))   \n",
    "    \n",
    "    y_true = keras.backend.less_equal(0.1,y_true)\n",
    "    y_true = keras.backend.cast(y_true, dtype='float32')\n",
    "    y_pred = keras.backend.less_equal(0.1,y_pred)\n",
    "    y_pred = keras.backend.cast(y_pred, dtype='float32')\n",
    "    \n",
    "    dice = 2*K.sum(y_true * y_pred)/(K.sum(y_true) + K.sum(y_pred) + 1e-2)\n",
    "    loss = MAE/dice \n",
    "    return loss\n",
    "\n",
    "\n",
    "def dice_score(y_true, y_pred):    \n",
    "    remove_NAs = y_true >= 0 \n",
    "    y_true = y_true[remove_NAs] \n",
    "    y_pred = y_pred[remove_NAs] \n",
    "    return (2*K.sum(y_true * y_pred)/(K.sum(y_true) + K.sum(y_pred) + 1e-2)) \n",
    "\n",
    "def mae(y_true, y_pred) :\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    \n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    \n",
    "    over_threshold = y_true >= 0.1\n",
    "    \n",
    "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
    "    \n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    \n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    \n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    \n",
    "    remove_NAs = y_true >= 0\n",
    "    \n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    \n",
    "    return(f1_score(y_true, y_pred))\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    \n",
    "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
    "\n",
    "def mae_keras(y_true, y_pred):  \n",
    "    score = tf.py_function(func=mae, inp=[y_true,y_pred], Tout=tf.float32, name = 'mae_keras') \n",
    "    return score   \n",
    "\n",
    "def dice_score_keras(y_true, y_pred): \n",
    "    score = tf.py_function(func=dice_score, inp=[y_true,y_pred],Tout=tf.float32,name = 'dice_score_keras')\n",
    "    return score \n",
    "\n",
    "\n",
    "def fscore_keras(y_true, y_pred):\n",
    "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
    "    return score\n",
    "\n",
    "def maeOverFscore_keras(y_true, y_pred):\n",
    "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ Fold 1 training ************\n",
      "rotate 90...\n",
      "rotate 270...\n",
      "train data shape...\n",
      "(47109, 40, 40, 10)\n",
      "(47109, 40, 40, 1)\n",
      "validation data shape...\n",
      "(15703, 40, 40, 10)\n",
      "(15703, 40, 40, 1)\n",
      "Train on 47109 samples, validate on 15703 samples\n",
      "Epoch 1/100\n",
      "47109/47109 [==============================] - 517s 11ms/sample - loss: 0.2589 - maeOverFscore_keras: 1.6409 - fscore_keras: 0.7947 - dice_score_keras: 8.1003 - mae_keras: 1.3046 - val_loss: 0.2556 - val_maeOverFscore_keras: 1.6261 - val_fscore_keras: 0.7993 - val_dice_score_keras: 8.5628 - val_mae_keras: 1.3004\n",
      "Epoch 2/100\n",
      "47109/47109 [==============================] - 496s 11ms/sample - loss: 0.2533 - maeOverFscore_keras: 1.6025 - fscore_keras: 0.7994 - dice_score_keras: 8.3637 - mae_keras: 1.2816 - val_loss: 0.2586 - val_maeOverFscore_keras: 1.6294 - val_fscore_keras: 0.8012 - val_dice_score_keras: 7.6013 - val_mae_keras: 1.3063\n",
      "Epoch 3/100\n",
      "47109/47109 [==============================] - 484s 10ms/sample - loss: 0.2515 - maeOverFscore_keras: 1.5949 - fscore_keras: 0.8011 - dice_score_keras: 8.4539 - mae_keras: 1.2780 - val_loss: 0.2540 - val_maeOverFscore_keras: 1.6106 - val_fscore_keras: 0.8007 - val_dice_score_keras: 8.1122 - val_mae_keras: 1.2908\n",
      "Epoch 4/100\n",
      "47109/47109 [==============================] - 487s 10ms/sample - loss: 0.2497 - maeOverFscore_keras: 1.5788 - fscore_keras: 0.8021 - dice_score_keras: 8.5522 - mae_keras: 1.2672 - val_loss: 0.2550 - val_maeOverFscore_keras: 1.5847 - val_fscore_keras: 0.8112 - val_dice_score_keras: 7.0902 - val_mae_keras: 1.2870\n",
      "Epoch 5/100\n",
      "47109/47109 [==============================] - 496s 11ms/sample - loss: 0.2492 - maeOverFscore_keras: 1.5761 - fscore_keras: 0.8026 - dice_score_keras: 8.6005 - mae_keras: 1.2656 - val_loss: 0.2518 - val_maeOverFscore_keras: 1.5849 - val_fscore_keras: 0.8110 - val_dice_score_keras: 7.3468 - val_mae_keras: 1.2866\n",
      "Epoch 6/100\n",
      "12448/47109 [======>.......................] - ETA: 5:20 - loss: 0.2449 - maeOverFscore_keras: 1.5575 - fscore_keras: 0.8031 - dice_score_keras: 8.6276 - mae_keras: 1.2503"
     ]
    }
   ],
   "source": [
    "def k_fold(k,files):  \n",
    "    folds = [] \n",
    "    fold_size = len(files) // k \n",
    "    for i in range(k): \n",
    "        if i == k-1:  \n",
    "            l = files[i*fold_size:] \n",
    "        else: \n",
    "            l = files[i*fold_size:(i+1)*fold_size]  \n",
    "        folds.append(l)   \n",
    "    return folds  \n",
    "\n",
    "def k_fold_train(k,x_train,y_train):  \n",
    "    x_folds = k_fold(k,x_train) \n",
    "    y_folds = k_fold(k,y_train) \n",
    "    for t in range(k):  \n",
    "        print(\"************ Fold {} training ************\".format(t+1))\n",
    "        if t == 1: \n",
    "            continue \n",
    "        cur_val_x = x_folds[t] \n",
    "        cur_val_y = y_folds[t] \n",
    "        train_folds_x = x_folds[0:t] + x_folds[t+1:] \n",
    "        train_folds_y = y_folds[0:t] + y_folds[t+1:]  \n",
    "        cur_train_x = [] \n",
    "        cur_train_y = [] \n",
    "        for j in train_folds_x:  \n",
    "            for q in j:  \n",
    "                cur_train_x.append(q) \n",
    "        for j in train_folds_y:  \n",
    "            for q in j:  \n",
    "                cur_train_y.append(q)  \n",
    "\n",
    "                \n",
    "        cur_train_x = np.asarray(cur_train_x) \n",
    "        cur_train_y = np.asarray(cur_train_y) \n",
    "        cur_train_x = cur_train_x.reshape((-1,40,40,10)) \n",
    "        cur_train_y = cur_train_y.reshape((-1,40,40,1)) \n",
    "        \n",
    "        cur_val_x = np.asarray(cur_val_x) \n",
    "        cur_val_y = np.asarray(cur_val_y) \n",
    "        cur_val_x = cur_val_x.reshape((-1,40,40,10)) \n",
    "        cur_val_y = cur_val_y.reshape((-1,40,40,1)) \n",
    "        \n",
    "        # augment data for cur_train_x and cur_train_y \n",
    "        print(\"rotate 90...\")\n",
    "        rotate_X_90 = np.zeros_like(cur_train_x)\n",
    "        rotate_Y_90 = np.zeros_like(cur_train_y)  \n",
    "        for j in range(rotate_X_90.shape[0]):\n",
    "            rotate_x=np.zeros([cur_train_x.shape[1],cur_train_x.shape[2],10])\n",
    "            rotate_y=np.zeros([cur_train_x.shape[1],cur_train_x.shape[2],1])\n",
    "            for i in range(10):\n",
    "                rotate_x[:,:,i]=np.rot90(cur_train_x[j,:,:,i])\n",
    "            rotate_y[:,:,0]=np.rot90(cur_train_y[j,:,:,0])\n",
    "            rotate_X_90[j,:,:,:] = rotate_x\n",
    "            rotate_Y_90[j,:,:,:] = rotate_y\n",
    "\n",
    "    \n",
    "        print(\"rotate 270...\")\n",
    "        rotate_X_270 = np.zeros_like(cur_train_x)\n",
    "        rotate_Y_270 = np.zeros_like(cur_train_y)\n",
    "        for j in range(rotate_X_270.shape[0]):\n",
    "            rotate_x=np.zeros([cur_train_x.shape[1],cur_train_x.shape[2],10])\n",
    "            rotate_y=np.zeros([cur_train_x.shape[1],cur_train_x.shape[2],1])\n",
    "            for i in range(10):\n",
    "                rotate_x[:,:,i]=np.rot90(cur_train_x[j,:,:,i])\n",
    "                rotate_x[:,:,i]=np.rot90(rotate_x[:,:,i])\n",
    "                rotate_x[:,:,i]=np.rot90(rotate_x[:,:,i])\n",
    "            rotate_y[:,:,0]=np.rot90(cur_train_y[j,:,:,0])\n",
    "            rotate_y[:,:,0]=np.rot90(rotate_y[:,:,0])\n",
    "            rotate_y[:,:,0]=np.rot90(rotate_y[:,:,0])\n",
    "            rotate_X_270[j,:,:,:] = rotate_x\n",
    "            rotate_Y_270[j,:,:,:] = rotate_y\n",
    "\n",
    "        cur_train_x = np.concatenate((cur_train_x, rotate_X_90, rotate_X_270), axis = 0)\n",
    "        cur_train_y = np.concatenate((cur_train_y, rotate_Y_90, rotate_Y_270), axis = 0)\n",
    "        del rotate_X_90, rotate_Y_90, rotate_X_270, rotate_Y_270 \n",
    "\n",
    "        \n",
    "        print(\"train data shape...\")\n",
    "        print(cur_train_x.shape) \n",
    "        print(cur_train_y.shape)\n",
    "        print(\"validation data shape...\")\n",
    "        print(cur_val_x.shape) \n",
    "        print(cur_val_y.shape) \n",
    "        # start training \n",
    "        input_layer = Input((40, 40, 10))\n",
    "        model = build_model(input_layer)  \n",
    "        model.compile(loss=custom_loss, optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras, dice_score_keras, mae_keras])\n",
    "        model.load_weights('./storage/base_model4/kfold2/model41.h5')\n",
    "        model_checkpoint = keras.callbacks.ModelCheckpoint('./storage/base_model5/kfold'+str(t+1)+'/model{epoch:02d}.h5',period=1)\n",
    "        lr_adjust = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.8) \n",
    "        model_history = model.fit(cur_train_x, cur_train_y ,epochs = 100, callbacks = [model_checkpoint,lr_adjust], validation_data = (cur_val_x, cur_val_y), shuffle = True,verbose = 1)\n",
    "\n",
    "k_fold_train(2,x_train,y_train) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
